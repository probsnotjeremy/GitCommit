{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ce1a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53726ff0cef04830a2338607de7b1f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 102 tokens\n",
      "Generated 120 tokens\n",
      "Generated 35 tokens\n",
      "Generated 59 tokens\n",
      "Generated 38 tokens\n",
      "Generated 24 tokens\n",
      "Generated 18 tokens\n",
      "Generated 128 tokens\n",
      "Generated 42 tokens\n",
      "Generated 36 tokens\n",
      "Generated 40 tokens\n",
      "Generated 16 tokens\n",
      "Generated 40 tokens\n",
      "Generated 106 tokens\n",
      "Generated 3 tokens\n",
      "Generated 22 tokens\n",
      "Generated 81 tokens\n",
      "Generated 38 tokens\n",
      "Generated 10 tokens\n",
      "Generated 38 tokens\n",
      "Saved Test #4 (140.16s) with 20 results to TestResults.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import nltk\n",
    "import time\n",
    "import datetime\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --------------------------\n",
    "# Global vars\n",
    "# --------------------------\n",
    "history = []\n",
    "ds = load_dataset(\"sentence-transformers/natural-questions\")\n",
    "dataset_split = ds[\"train\"]\n",
    "filename = \"TestResults.json\"\n",
    "\n",
    "# --------------------------\n",
    "# Setup model + tokenizer\n",
    "# --------------------------\n",
    "model_id = \"microsoft/phi-2\"\n",
    "\n",
    "stopwords = {\"the\", \"a\", \"and\", \"is\", \"to\", \"of\", \"in\", \"on\"}\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_skip_modules=None,\n",
    "    llm_int8_enable_fp32_cpu_offload=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.float16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "# --------------------------\n",
    "# WordNet setup\n",
    "# --------------------------\n",
    "try:\n",
    "    from nltk.corpus import wordnet\n",
    "    _ = wordnet.synsets(\"car\")\n",
    "except LookupError:\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"omw-1.4\")\n",
    "    from nltk.corpus import wordnet\n",
    "\n",
    "# --------------------------\n",
    "# SentenceTransformer setup\n",
    "# --------------------------\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "\n",
    "# --------------------------\n",
    "# LLM wrapper\n",
    "# --------------------------\n",
    "def ask_phi2(user_input, max_new_tokens=128):\n",
    "    global history\n",
    "    history.append(f\"User: {user_input}\")\n",
    "    prompt = \"\\n\".join(history) + \"\\nAssistant:\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    # Decode only new tokens (not the prompt)\n",
    "    gen_ids = output_ids[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    print(f\"Generated {len(gen_ids)} tokens\")\n",
    "\n",
    "    history.append(f\"Assistant: {response}\")\n",
    "    return response\n",
    "\n",
    "\n",
    "def send_to_llm(question):\n",
    "    global history\n",
    "    history = []  # reset history per question\n",
    "    return ask_phi2(question, max_new_tokens=128)\n",
    "\n",
    "# --------------------------\n",
    "# Text utilities\n",
    "# --------------------------\n",
    "def clean_words(text):\n",
    "    return [w.lower() for w in text.split() if w.lower() not in stopwords]\n",
    "\n",
    "def expand_with_synonyms(words):\n",
    "    expanded = set(words)\n",
    "    for w in words:\n",
    "        for syn in wordnet.synsets(w):\n",
    "            for lemma in syn.lemmas():\n",
    "                expanded.add(lemma.name().lower().replace(\"_\", \" \"))\n",
    "    return expanded\n",
    "\n",
    "def overlap_percent(answer, response, use_synonyms=True):\n",
    "    a_words = clean_words(answer)\n",
    "    r_words = clean_words(response)\n",
    "\n",
    "    if use_synonyms:\n",
    "        a_set = expand_with_synonyms(a_words)\n",
    "        r_set = expand_with_synonyms(r_words)\n",
    "    else:\n",
    "        a_set, r_set = set(a_words), set(r_words)\n",
    "\n",
    "    if not a_set:\n",
    "        return 0\n",
    "    return len(a_set & r_set) / len(a_set) * 100\n",
    "\n",
    "def semantic_percent(answer, response):\n",
    "    # Compute embeddings and cosine similarity\n",
    "    emb_a = embedder.encode(answer, convert_to_tensor=True)\n",
    "    emb_r = embedder.encode(response, convert_to_tensor=True)\n",
    "    sim = util.pytorch_cos_sim(emb_a, emb_r).item()\n",
    "    return sim * 100  # percentage\n",
    "\n",
    "# --------------------------\n",
    "# Table Results\n",
    "# --------------------------\n",
    "\n",
    "def summarize_results(df):\n",
    "    summary = (\n",
    "        df.groupby(\"test_number\")\n",
    "          .agg(\n",
    "              n_questions=(\"question\", \"count\"),\n",
    "              avg_overlap=(\"overlap_percent\", \"mean\"),\n",
    "              avg_semantic=(\"semantic_percent\", \"mean\"),\n",
    "              duration_seconds=(\"duration_seconds\", \"first\"),\n",
    "              timestamp=(\"timestamp\", \"first\")\n",
    "          )\n",
    "          .reset_index()\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "\n",
    "def load_results_as_table(filename=\"TestResults.json\"):\n",
    "    with open(filename, \"r\") as f:\n",
    "        all_results = json.load(f)\n",
    "\n",
    "    # Flatten into a list of rows\n",
    "    rows = []\n",
    "    for test in all_results:\n",
    "        for r in test[\"results\"]:\n",
    "            rows.append({\n",
    "                \"test_number\": test[\"test_number\"],\n",
    "                \"timestamp\": test[\"timestamp\"],\n",
    "                \"duration_seconds\": test[\"duration_seconds\"],\n",
    "                \"question\": r[\"question\"],\n",
    "                \"expected_answer\": r[\"expected_answer\"],\n",
    "                \"llm_response\": r[\"llm_response\"],\n",
    "                \"overlap_percent\": r[\"overlap_percent\"],\n",
    "                \"semantic_percent\": r[\"semantic_percent\"]\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# --------------------------\n",
    "# Experiment helpers\n",
    "# --------------------------\n",
    "def run_experiment(dataset_split, n=20):\n",
    "    #questions = dataset_split[\"query\"]\n",
    "    #answers = dataset_split[\"answer\"]\n",
    "    #pairs = list(zip(questions, answers))\n",
    "\n",
    "    idxs = random.sample(range(len(dataset_split)), min(n, len(dataset_split)))\n",
    "    subset = [dataset_split[i] for i in idxs]  # only N rows, lazy load\n",
    "\n",
    "    #subset = random.sample(pairs, min(n, len(pairs)))\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, row in enumerate(subset):\n",
    "        q, a = row[\"query\"], row[\"answer\"]\n",
    "        resp = send_to_llm(q)\n",
    "        overlap_score = overlap_percent(a, resp, use_synonyms=True)\n",
    "        semantic_score = semantic_percent(a, resp)\n",
    "\n",
    "        results.append({\n",
    "            \"id\": i,\n",
    "            \"question\": q,\n",
    "            \"expected_answer\": a,\n",
    "            \"llm_response\": resp,\n",
    "            \"overlap_percent\": round(overlap_score, 2),\n",
    "            \"semantic_percent\": round(semantic_score, 2)\n",
    "        })\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    return results, duration\n",
    "\n",
    "\n",
    "def save_results(results, duration, filename=\"TestResults.json\"):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = []\n",
    "\n",
    "    test_number = len(all_results) + 1\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Compute averages\n",
    "    avg_overlap = sum(r[\"overlap_percent\"] for r in results) / len(results)\n",
    "    avg_semantic = sum(r[\"semantic_percent\"] for r in results) / len(results)\n",
    "\n",
    "    all_results.append({\n",
    "        \"test_number\": test_number,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"duration_seconds\": round(duration, 2),\n",
    "        \"n_questions\": len(results),\n",
    "        \"avg_overlap\": round(avg_overlap, 2),\n",
    "        \"avg_semantic\": round(avg_semantic, 2),\n",
    "        \"results\": results\n",
    "    })\n",
    "\n",
    "\n",
    "    # Write to a temp file first\n",
    "    with tempfile.NamedTemporaryFile(\"w\", delete=False) as tmp:\n",
    "        json.dump(all_results, tmp, indent=2)\n",
    "        tempname = tmp.name\n",
    "\n",
    "    shutil.move(tempname, filename)\n",
    "\n",
    "    print(f\"Saved Test #{test_number} ({round(duration,2)}s) with {len(results)} results to {filename}\")\n",
    "\n",
    "# --------------------------\n",
    "# Main\n",
    "# --------------------------\n",
    "def main(n=20):\n",
    "    results, duration = run_experiment(dataset_split, n=n)\n",
    "    save_results(results, duration)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a915dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Test #2 (160.29s) with 20 results to TestResults.json\n"
     ]
    }
   ],
   "source": [
    "main(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e09d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_number  n_questions  avg_overlap  avg_semantic  duration_seconds  \\\n",
      "0            1            5       7.1420       41.6980             15.34   \n",
      "1            2           20      18.2995       54.9925            160.29   \n",
      "2            3           20      10.4930       53.4155            110.53   \n",
      "3            4           20      17.0635       59.8345            140.16   \n",
      "\n",
      "             timestamp  \n",
      "0  2025-09-07 19:13:38  \n",
      "1  2025-09-07 19:16:48  \n",
      "2  2025-09-07 19:22:25  \n",
      "3  2025-09-07 19:31:05  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_number</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>question</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>overlap_percent</th>\n",
       "      <th>semantic_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-07 19:13:38</td>\n",
       "      <td>15.34</td>\n",
       "      <td>who sang you don't have to be a star baby</td>\n",
       "      <td>You Don't Have to Be a Star (To Be in My Show)...</td>\n",
       "      <td>Whitney Houston, \"I Will Always Love You\"</td>\n",
       "      <td>6.05</td>\n",
       "      <td>34.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-07 19:13:38</td>\n",
       "      <td>15.34</td>\n",
       "      <td>who jumped from the tree in a separate peace</td>\n",
       "      <td>A Separate Peace Gene Forrester, the protagoni...</td>\n",
       "      <td>The person who jumped from the tree is unknown.</td>\n",
       "      <td>0.77</td>\n",
       "      <td>15.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-07 19:13:38</td>\n",
       "      <td>15.34</td>\n",
       "      <td>what is the house edge of three card poker</td>\n",
       "      <td>Three card poker Ante and Play house advantage...</td>\n",
       "      <td>The house edge for a game of 3-Card Poker is a...</td>\n",
       "      <td>28.89</td>\n",
       "      <td>65.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-07 19:13:38</td>\n",
       "      <td>15.34</td>\n",
       "      <td>who was the leading scorer in the mavs game 1 ...</td>\n",
       "      <td>2006 NBA Finals Dallas' Jason Terry scored a p...</td>\n",
       "      <td>Tim Duncan, with 24 points.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-07 19:13:38</td>\n",
       "      <td>15.34</td>\n",
       "      <td>what is malcolm's last name in malcolm in the ...</td>\n",
       "      <td>List of Malcolm in the Middle characters In th...</td>\n",
       "      <td>Malcom.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-07 19:31:05</td>\n",
       "      <td>140.16</td>\n",
       "      <td>who played peggy biggs on mike and molly</td>\n",
       "      <td>Rondi Reed She appeared in the Seinfeld episod...</td>\n",
       "      <td>The actor's name is Peggy Biggs, and she starr...</td>\n",
       "      <td>11.36</td>\n",
       "      <td>74.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-07 19:31:05</td>\n",
       "      <td>140.16</td>\n",
       "      <td>who was in charge of russia during the cold war</td>\n",
       "      <td>Cold War While most historians trace its origi...</td>\n",
       "      <td>The leader of Russia during the Cold War was J...</td>\n",
       "      <td>14.87</td>\n",
       "      <td>54.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-07 19:31:05</td>\n",
       "      <td>140.16</td>\n",
       "      <td>who has become the first batsman to score thre...</td>\n",
       "      <td>Twenty20 International The game had initially ...</td>\n",
       "      <td>Rohit Sharma from India became the first batsm...</td>\n",
       "      <td>10.82</td>\n",
       "      <td>63.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-07 19:31:05</td>\n",
       "      <td>140.16</td>\n",
       "      <td>where does the money for escrow come from</td>\n",
       "      <td>Escrow An escrow is a contractual arrangement ...</td>\n",
       "      <td>Where does the money for Escrow go?</td>\n",
       "      <td>1.17</td>\n",
       "      <td>69.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-07 19:31:05</td>\n",
       "      <td>140.16</td>\n",
       "      <td>what is the name of jacob tribe in twilight</td>\n",
       "      <td>Jacob Black In New Moon, Jacob's character is ...</td>\n",
       "      <td>The Jacobites, also known as the Clan Stuart o...</td>\n",
       "      <td>3.97</td>\n",
       "      <td>21.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_number            timestamp  duration_seconds  \\\n",
       "0             1  2025-09-07 19:13:38             15.34   \n",
       "1             1  2025-09-07 19:13:38             15.34   \n",
       "2             1  2025-09-07 19:13:38             15.34   \n",
       "3             1  2025-09-07 19:13:38             15.34   \n",
       "4             1  2025-09-07 19:13:38             15.34   \n",
       "..          ...                  ...               ...   \n",
       "60            4  2025-09-07 19:31:05            140.16   \n",
       "61            4  2025-09-07 19:31:05            140.16   \n",
       "62            4  2025-09-07 19:31:05            140.16   \n",
       "63            4  2025-09-07 19:31:05            140.16   \n",
       "64            4  2025-09-07 19:31:05            140.16   \n",
       "\n",
       "                                             question  \\\n",
       "0           who sang you don't have to be a star baby   \n",
       "1        who jumped from the tree in a separate peace   \n",
       "2          what is the house edge of three card poker   \n",
       "3   who was the leading scorer in the mavs game 1 ...   \n",
       "4   what is malcolm's last name in malcolm in the ...   \n",
       "..                                                ...   \n",
       "60           who played peggy biggs on mike and molly   \n",
       "61    who was in charge of russia during the cold war   \n",
       "62  who has become the first batsman to score thre...   \n",
       "63          where does the money for escrow come from   \n",
       "64        what is the name of jacob tribe in twilight   \n",
       "\n",
       "                                      expected_answer  \\\n",
       "0   You Don't Have to Be a Star (To Be in My Show)...   \n",
       "1   A Separate Peace Gene Forrester, the protagoni...   \n",
       "2   Three card poker Ante and Play house advantage...   \n",
       "3   2006 NBA Finals Dallas' Jason Terry scored a p...   \n",
       "4   List of Malcolm in the Middle characters In th...   \n",
       "..                                                ...   \n",
       "60  Rondi Reed She appeared in the Seinfeld episod...   \n",
       "61  Cold War While most historians trace its origi...   \n",
       "62  Twenty20 International The game had initially ...   \n",
       "63  Escrow An escrow is a contractual arrangement ...   \n",
       "64  Jacob Black In New Moon, Jacob's character is ...   \n",
       "\n",
       "                                         llm_response  overlap_percent  \\\n",
       "0           Whitney Houston, \"I Will Always Love You\"             6.05   \n",
       "1     The person who jumped from the tree is unknown.             0.77   \n",
       "2   The house edge for a game of 3-Card Poker is a...            28.89   \n",
       "3                         Tim Duncan, with 24 points.             0.00   \n",
       "4                                             Malcom.             0.00   \n",
       "..                                                ...              ...   \n",
       "60  The actor's name is Peggy Biggs, and she starr...            11.36   \n",
       "61  The leader of Russia during the Cold War was J...            14.87   \n",
       "62  Rohit Sharma from India became the first batsm...            10.82   \n",
       "63                Where does the money for Escrow go?             1.17   \n",
       "64  The Jacobites, also known as the Clan Stuart o...             3.97   \n",
       "\n",
       "    semantic_percent  \n",
       "0              34.70  \n",
       "1              15.06  \n",
       "2              65.20  \n",
       "3              54.53  \n",
       "4              39.00  \n",
       "..               ...  \n",
       "60             74.55  \n",
       "61             54.03  \n",
       "62             63.93  \n",
       "63             69.35  \n",
       "64             21.41  \n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_results_as_table()\n",
    "summary = summarize_results(df)\n",
    "print(summary)\n",
    "df.head(90)\n",
    "# Look into unfloss for fine-tuning. rank and alpha\n",
    "# Look into how github works and fork intersting projects to add onto. Possibly send pull requests for possibility to merge into actual file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vLLM)",
   "language": "python",
   "name": "vllm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
