{
  "best_global_step": 12000,
  "best_metric": 4.202101707458496,
  "best_model_checkpoint": "./qlora_phi2\\checkpoint-12000",
  "epoch": 0.5041010722649891,
  "eval_steps": 400,
  "global_step": 12000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0010502105672187273,
      "grad_norm": 18.66478729248047,
      "learning_rate": 0.0001997920583076907,
      "loss": 5.1212,
      "step": 100
    },
    {
      "epoch": 0.0021004211344374545,
      "grad_norm": 5.977574825286865,
      "learning_rate": 0.00019958201619424694,
      "loss": 4.621,
      "step": 200
    },
    {
      "epoch": 0.003150631701656182,
      "grad_norm": 7.137847423553467,
      "learning_rate": 0.0001993719740808032,
      "loss": 4.1328,
      "step": 300
    },
    {
      "epoch": 0.004200842268874909,
      "grad_norm": 6.00375509262085,
      "learning_rate": 0.00019916193196735946,
      "loss": 4.2954,
      "step": 400
    },
    {
      "epoch": 0.004200842268874909,
      "eval_loss": 4.5237040519714355,
      "eval_runtime": 531.4607,
      "eval_samples_per_second": 0.941,
      "eval_steps_per_second": 0.941,
      "step": 400
    },
    {
      "epoch": 0.005251052836093637,
      "grad_norm": 6.13330078125,
      "learning_rate": 0.00019895188985391573,
      "loss": 4.3205,
      "step": 500
    },
    {
      "epoch": 0.006301263403312364,
      "grad_norm": 3.3158416748046875,
      "learning_rate": 0.00019874184774047198,
      "loss": 4.2788,
      "step": 600
    },
    {
      "epoch": 0.007351473970531091,
      "grad_norm": 1.9965342283248901,
      "learning_rate": 0.00019853180562702822,
      "loss": 4.4543,
      "step": 700
    },
    {
      "epoch": 0.008401684537749818,
      "grad_norm": 2.850419759750366,
      "learning_rate": 0.0001983217635135845,
      "loss": 4.457,
      "step": 800
    },
    {
      "epoch": 0.008401684537749818,
      "eval_loss": 4.606669902801514,
      "eval_runtime": 670.9925,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 800
    },
    {
      "epoch": 0.009451895104968546,
      "grad_norm": 7.501120567321777,
      "learning_rate": 0.00019811172140014074,
      "loss": 4.2665,
      "step": 900
    },
    {
      "epoch": 0.010502105672187274,
      "grad_norm": 1.6431397199630737,
      "learning_rate": 0.000197901679286697,
      "loss": 4.205,
      "step": 1000
    },
    {
      "epoch": 0.011552316239406,
      "grad_norm": 3.0278685092926025,
      "learning_rate": 0.00019769163717325326,
      "loss": 4.0099,
      "step": 1100
    },
    {
      "epoch": 0.012602526806624728,
      "grad_norm": 2.6421611309051514,
      "learning_rate": 0.0001974815950598095,
      "loss": 4.0807,
      "step": 1200
    },
    {
      "epoch": 0.012602526806624728,
      "eval_loss": 4.467739582061768,
      "eval_runtime": 623.0366,
      "eval_samples_per_second": 0.803,
      "eval_steps_per_second": 0.803,
      "step": 1200
    },
    {
      "epoch": 0.013652737373843456,
      "grad_norm": 3.8290793895721436,
      "learning_rate": 0.00019727155294636575,
      "loss": 4.1455,
      "step": 1300
    },
    {
      "epoch": 0.014702947941062182,
      "grad_norm": 6.508715629577637,
      "learning_rate": 0.00019706151083292203,
      "loss": 4.3793,
      "step": 1400
    },
    {
      "epoch": 0.01575315850828091,
      "grad_norm": 9.706954956054688,
      "learning_rate": 0.00019685146871947827,
      "loss": 4.2705,
      "step": 1500
    },
    {
      "epoch": 0.016803369075499636,
      "grad_norm": 5.44171142578125,
      "learning_rate": 0.00019664142660603452,
      "loss": 4.3585,
      "step": 1600
    },
    {
      "epoch": 0.016803369075499636,
      "eval_loss": 4.442878723144531,
      "eval_runtime": 564.6753,
      "eval_samples_per_second": 0.885,
      "eval_steps_per_second": 0.885,
      "step": 1600
    },
    {
      "epoch": 0.017853579642718366,
      "grad_norm": 2.4329235553741455,
      "learning_rate": 0.00019643138449259076,
      "loss": 4.1497,
      "step": 1700
    },
    {
      "epoch": 0.018903790209937092,
      "grad_norm": 6.474256992340088,
      "learning_rate": 0.000196221342379147,
      "loss": 3.9367,
      "step": 1800
    },
    {
      "epoch": 0.01995400077715582,
      "grad_norm": 5.269887447357178,
      "learning_rate": 0.00019601130026570328,
      "loss": 4.3266,
      "step": 1900
    },
    {
      "epoch": 0.021004211344374548,
      "grad_norm": 2.3468480110168457,
      "learning_rate": 0.00019580125815225953,
      "loss": 4.3942,
      "step": 2000
    },
    {
      "epoch": 0.021004211344374548,
      "eval_loss": 4.582596778869629,
      "eval_runtime": 671.0212,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 2000
    },
    {
      "epoch": 0.022054421911593274,
      "grad_norm": 2.6442692279815674,
      "learning_rate": 0.00019559121603881578,
      "loss": 4.4985,
      "step": 2100
    },
    {
      "epoch": 0.023104632478812,
      "grad_norm": 5.494149684906006,
      "learning_rate": 0.00019538117392537205,
      "loss": 4.0987,
      "step": 2200
    },
    {
      "epoch": 0.02415484304603073,
      "grad_norm": 1.540907859802246,
      "learning_rate": 0.0001951711318119283,
      "loss": 4.5078,
      "step": 2300
    },
    {
      "epoch": 0.025205053613249456,
      "grad_norm": 1.920764684677124,
      "learning_rate": 0.00019496108969848454,
      "loss": 4.522,
      "step": 2400
    },
    {
      "epoch": 0.025205053613249456,
      "eval_loss": 4.452702045440674,
      "eval_runtime": 670.9677,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 2400
    },
    {
      "epoch": 0.026255264180468182,
      "grad_norm": 3.835669994354248,
      "learning_rate": 0.0001947510475850408,
      "loss": 4.3552,
      "step": 2500
    },
    {
      "epoch": 0.027305474747686912,
      "grad_norm": 1.9717521667480469,
      "learning_rate": 0.00019454100547159706,
      "loss": 4.2136,
      "step": 2600
    },
    {
      "epoch": 0.02835568531490564,
      "grad_norm": 2.0211572647094727,
      "learning_rate": 0.00019433096335815333,
      "loss": 3.9063,
      "step": 2700
    },
    {
      "epoch": 0.029405895882124364,
      "grad_norm": 1.4198241233825684,
      "learning_rate": 0.00019412092124470958,
      "loss": 4.2998,
      "step": 2800
    },
    {
      "epoch": 0.029405895882124364,
      "eval_loss": 4.368912696838379,
      "eval_runtime": 671.0972,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 2800
    },
    {
      "epoch": 0.030456106449343094,
      "grad_norm": 3.6630115509033203,
      "learning_rate": 0.00019391087913126582,
      "loss": 3.8254,
      "step": 2900
    },
    {
      "epoch": 0.03150631701656182,
      "grad_norm": 2.405656099319458,
      "learning_rate": 0.0001937008370178221,
      "loss": 4.066,
      "step": 3000
    },
    {
      "epoch": 0.032556527583780547,
      "grad_norm": 2.7973239421844482,
      "learning_rate": 0.00019349079490437834,
      "loss": 3.7951,
      "step": 3100
    },
    {
      "epoch": 0.03360673815099927,
      "grad_norm": 5.34809684753418,
      "learning_rate": 0.0001932807527909346,
      "loss": 4.1031,
      "step": 3200
    },
    {
      "epoch": 0.03360673815099927,
      "eval_loss": 4.521541595458984,
      "eval_runtime": 670.8922,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 3200
    },
    {
      "epoch": 0.034656948718218006,
      "grad_norm": 2.7876393795013428,
      "learning_rate": 0.00019307071067749086,
      "loss": 4.2864,
      "step": 3300
    },
    {
      "epoch": 0.03570715928543673,
      "grad_norm": 3.1132044792175293,
      "learning_rate": 0.0001928606685640471,
      "loss": 4.3161,
      "step": 3400
    },
    {
      "epoch": 0.03675736985265546,
      "grad_norm": 3.05275559425354,
      "learning_rate": 0.00019265062645060335,
      "loss": 4.4318,
      "step": 3500
    },
    {
      "epoch": 0.037807580419874184,
      "grad_norm": 6.497086524963379,
      "learning_rate": 0.00019244058433715963,
      "loss": 4.4095,
      "step": 3600
    },
    {
      "epoch": 0.037807580419874184,
      "eval_loss": 4.378541946411133,
      "eval_runtime": 670.8032,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 3600
    },
    {
      "epoch": 0.03885779098709291,
      "grad_norm": 5.04200553894043,
      "learning_rate": 0.00019223054222371587,
      "loss": 4.1311,
      "step": 3700
    },
    {
      "epoch": 0.03990800155431164,
      "grad_norm": 3.3184375762939453,
      "learning_rate": 0.00019202050011027212,
      "loss": 4.4531,
      "step": 3800
    },
    {
      "epoch": 0.04095821212153037,
      "grad_norm": 3.2039339542388916,
      "learning_rate": 0.00019181045799682836,
      "loss": 4.2619,
      "step": 3900
    },
    {
      "epoch": 0.042008422688749096,
      "grad_norm": 1.6201894283294678,
      "learning_rate": 0.0001916004158833846,
      "loss": 4.2902,
      "step": 4000
    },
    {
      "epoch": 0.042008422688749096,
      "eval_loss": 4.418441295623779,
      "eval_runtime": 670.8263,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 4000
    },
    {
      "epoch": 0.04305863325596782,
      "grad_norm": 3.216090440750122,
      "learning_rate": 0.00019139037376994088,
      "loss": 4.0635,
      "step": 4100
    },
    {
      "epoch": 0.04410884382318655,
      "grad_norm": 2.054702043533325,
      "learning_rate": 0.00019118033165649713,
      "loss": 4.1805,
      "step": 4200
    },
    {
      "epoch": 0.045159054390405275,
      "grad_norm": 2.268874168395996,
      "learning_rate": 0.00019097028954305337,
      "loss": 4.0876,
      "step": 4300
    },
    {
      "epoch": 0.046209264957624,
      "grad_norm": 2.249051094055176,
      "learning_rate": 0.00019076024742960965,
      "loss": 4.1963,
      "step": 4400
    },
    {
      "epoch": 0.046209264957624,
      "eval_loss": 4.377742290496826,
      "eval_runtime": 670.9915,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 4400
    },
    {
      "epoch": 0.047259475524842734,
      "grad_norm": 1.2700098752975464,
      "learning_rate": 0.0001905502053161659,
      "loss": 3.6943,
      "step": 4500
    },
    {
      "epoch": 0.04830968609206146,
      "grad_norm": 1.6984496116638184,
      "learning_rate": 0.00019034016320272217,
      "loss": 4.1575,
      "step": 4600
    },
    {
      "epoch": 0.049359896659280186,
      "grad_norm": 4.563112735748291,
      "learning_rate": 0.0001901301210892784,
      "loss": 3.8412,
      "step": 4700
    },
    {
      "epoch": 0.05041010722649891,
      "grad_norm": 2.923128128051758,
      "learning_rate": 0.00018992007897583466,
      "loss": 3.7878,
      "step": 4800
    },
    {
      "epoch": 0.05041010722649891,
      "eval_loss": 4.360812664031982,
      "eval_runtime": 670.8097,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 4800
    },
    {
      "epoch": 0.05146031779371764,
      "grad_norm": 3.2823996543884277,
      "learning_rate": 0.00018971003686239093,
      "loss": 4.0115,
      "step": 4900
    },
    {
      "epoch": 0.052510528360936365,
      "grad_norm": 1.6243579387664795,
      "learning_rate": 0.00018949999474894718,
      "loss": 3.965,
      "step": 5000
    },
    {
      "epoch": 0.0535607389281551,
      "grad_norm": 1.681735873222351,
      "learning_rate": 0.00018928995263550342,
      "loss": 4.3855,
      "step": 5100
    },
    {
      "epoch": 0.054610949495373824,
      "grad_norm": 4.092941761016846,
      "learning_rate": 0.0001890799105220597,
      "loss": 4.1672,
      "step": 5200
    },
    {
      "epoch": 0.054610949495373824,
      "eval_loss": 4.322641372680664,
      "eval_runtime": 670.8002,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 5200
    },
    {
      "epoch": 0.05566116006259255,
      "grad_norm": 3.276567220687866,
      "learning_rate": 0.00018886986840861594,
      "loss": 4.2328,
      "step": 5300
    },
    {
      "epoch": 0.05671137062981128,
      "grad_norm": 2.5074918270111084,
      "learning_rate": 0.0001886598262951722,
      "loss": 4.2138,
      "step": 5400
    },
    {
      "epoch": 0.05776158119703,
      "grad_norm": 3.4743261337280273,
      "learning_rate": 0.00018844978418172846,
      "loss": 3.647,
      "step": 5500
    },
    {
      "epoch": 0.05881179176424873,
      "grad_norm": 3.8492350578308105,
      "learning_rate": 0.0001882397420682847,
      "loss": 4.1602,
      "step": 5600
    },
    {
      "epoch": 0.05881179176424873,
      "eval_loss": 4.391132831573486,
      "eval_runtime": 670.9236,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 5600
    },
    {
      "epoch": 0.05986200233146746,
      "grad_norm": 2.9264931678771973,
      "learning_rate": 0.00018802969995484095,
      "loss": 4.2639,
      "step": 5700
    },
    {
      "epoch": 0.06091221289868619,
      "grad_norm": 3.6172077655792236,
      "learning_rate": 0.0001878196578413972,
      "loss": 4.3999,
      "step": 5800
    },
    {
      "epoch": 0.061962423465904914,
      "grad_norm": 2.6566433906555176,
      "learning_rate": 0.00018760961572795345,
      "loss": 4.0533,
      "step": 5900
    },
    {
      "epoch": 0.06301263403312364,
      "grad_norm": 1.8535627126693726,
      "learning_rate": 0.00018739957361450972,
      "loss": 4.1119,
      "step": 6000
    },
    {
      "epoch": 0.06301263403312364,
      "eval_loss": 4.53863525390625,
      "eval_runtime": 670.7912,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 6000
    },
    {
      "epoch": 0.06406284460034237,
      "grad_norm": 3.129136562347412,
      "learning_rate": 0.00018718953150106596,
      "loss": 4.1283,
      "step": 6100
    },
    {
      "epoch": 0.06511305516756109,
      "grad_norm": 2.1074867248535156,
      "learning_rate": 0.0001869794893876222,
      "loss": 3.843,
      "step": 6200
    },
    {
      "epoch": 0.06616326573477982,
      "grad_norm": 2.45322585105896,
      "learning_rate": 0.00018676944727417848,
      "loss": 4.0544,
      "step": 6300
    },
    {
      "epoch": 0.06721347630199855,
      "grad_norm": 1.9794223308563232,
      "learning_rate": 0.00018655940516073473,
      "loss": 4.0419,
      "step": 6400
    },
    {
      "epoch": 0.06721347630199855,
      "eval_loss": 4.2919745445251465,
      "eval_runtime": 670.8406,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 6400
    },
    {
      "epoch": 0.06826368686921727,
      "grad_norm": 2.9517412185668945,
      "learning_rate": 0.00018634936304729097,
      "loss": 3.9114,
      "step": 6500
    },
    {
      "epoch": 0.06931389743643601,
      "grad_norm": 1.6277990341186523,
      "learning_rate": 0.00018613932093384725,
      "loss": 4.5607,
      "step": 6600
    },
    {
      "epoch": 0.07036410800365474,
      "grad_norm": 1.9730528593063354,
      "learning_rate": 0.0001859292788204035,
      "loss": 3.9361,
      "step": 6700
    },
    {
      "epoch": 0.07141431857087346,
      "grad_norm": 2.7102396488189697,
      "learning_rate": 0.00018571923670695977,
      "loss": 3.6868,
      "step": 6800
    },
    {
      "epoch": 0.07141431857087346,
      "eval_loss": 4.539511680603027,
      "eval_runtime": 671.0405,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 6800
    },
    {
      "epoch": 0.07246452913809219,
      "grad_norm": 1.5984753370285034,
      "learning_rate": 0.000185509194593516,
      "loss": 4.3003,
      "step": 6900
    },
    {
      "epoch": 0.07351473970531092,
      "grad_norm": 1.5038682222366333,
      "learning_rate": 0.00018529915248007226,
      "loss": 4.049,
      "step": 7000
    },
    {
      "epoch": 0.07456495027252964,
      "grad_norm": 2.1288974285125732,
      "learning_rate": 0.00018508911036662853,
      "loss": 3.9913,
      "step": 7100
    },
    {
      "epoch": 0.07561516083974837,
      "grad_norm": 1.7999458312988281,
      "learning_rate": 0.00018487906825318478,
      "loss": 3.8858,
      "step": 7200
    },
    {
      "epoch": 0.07561516083974837,
      "eval_loss": 4.3332295417785645,
      "eval_runtime": 670.888,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 7200
    },
    {
      "epoch": 0.0766653714069671,
      "grad_norm": 1.695072889328003,
      "learning_rate": 0.00018466902613974102,
      "loss": 3.851,
      "step": 7300
    },
    {
      "epoch": 0.07771558197418582,
      "grad_norm": 1.6876589059829712,
      "learning_rate": 0.0001844589840262973,
      "loss": 4.0182,
      "step": 7400
    },
    {
      "epoch": 0.07876579254140455,
      "grad_norm": 1.3824230432510376,
      "learning_rate": 0.00018424894191285354,
      "loss": 4.1426,
      "step": 7500
    },
    {
      "epoch": 0.07981600310862327,
      "grad_norm": 5.697673320770264,
      "learning_rate": 0.0001840388997994098,
      "loss": 4.0493,
      "step": 7600
    },
    {
      "epoch": 0.07981600310862327,
      "eval_loss": 4.394565582275391,
      "eval_runtime": 671.1551,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 7600
    },
    {
      "epoch": 0.080866213675842,
      "grad_norm": 1.2622689008712769,
      "learning_rate": 0.00018382885768596606,
      "loss": 4.3085,
      "step": 7700
    },
    {
      "epoch": 0.08191642424306074,
      "grad_norm": 4.17305850982666,
      "learning_rate": 0.0001836188155725223,
      "loss": 4.2845,
      "step": 7800
    },
    {
      "epoch": 0.08296663481027947,
      "grad_norm": 2.453030824661255,
      "learning_rate": 0.00018340877345907855,
      "loss": 3.9541,
      "step": 7900
    },
    {
      "epoch": 0.08401684537749819,
      "grad_norm": 4.327960968017578,
      "learning_rate": 0.0001831987313456348,
      "loss": 4.2202,
      "step": 8000
    },
    {
      "epoch": 0.08401684537749819,
      "eval_loss": 4.359541893005371,
      "eval_runtime": 670.9263,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 8000
    },
    {
      "epoch": 0.08506705594471692,
      "grad_norm": 2.3143393993377686,
      "learning_rate": 0.00018298868923219104,
      "loss": 4.1187,
      "step": 8100
    },
    {
      "epoch": 0.08611726651193564,
      "grad_norm": 1.6743967533111572,
      "learning_rate": 0.00018277864711874732,
      "loss": 3.6532,
      "step": 8200
    },
    {
      "epoch": 0.08716747707915437,
      "grad_norm": 3.2888548374176025,
      "learning_rate": 0.00018256860500530356,
      "loss": 4.07,
      "step": 8300
    },
    {
      "epoch": 0.0882176876463731,
      "grad_norm": 1.3859567642211914,
      "learning_rate": 0.0001823585628918598,
      "loss": 4.1986,
      "step": 8400
    },
    {
      "epoch": 0.0882176876463731,
      "eval_loss": 4.380842208862305,
      "eval_runtime": 670.8944,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 8400
    },
    {
      "epoch": 0.08926789821359182,
      "grad_norm": 2.1183865070343018,
      "learning_rate": 0.00018214852077841608,
      "loss": 3.8035,
      "step": 8500
    },
    {
      "epoch": 0.09031810878081055,
      "grad_norm": 2.0141305923461914,
      "learning_rate": 0.00018193847866497233,
      "loss": 3.7718,
      "step": 8600
    },
    {
      "epoch": 0.09136831934802928,
      "grad_norm": 6.247004985809326,
      "learning_rate": 0.00018172843655152857,
      "loss": 4.1594,
      "step": 8700
    },
    {
      "epoch": 0.092418529915248,
      "grad_norm": 1.36457359790802,
      "learning_rate": 0.00018151839443808485,
      "loss": 3.9258,
      "step": 8800
    },
    {
      "epoch": 0.092418529915248,
      "eval_loss": 4.411832809448242,
      "eval_runtime": 667.1241,
      "eval_samples_per_second": 0.749,
      "eval_steps_per_second": 0.749,
      "step": 8800
    },
    {
      "epoch": 0.09346874048246673,
      "grad_norm": 4.733314037322998,
      "learning_rate": 0.0001813083523246411,
      "loss": 3.9726,
      "step": 8900
    },
    {
      "epoch": 0.09451895104968547,
      "grad_norm": 1.979238510131836,
      "learning_rate": 0.00018109831021119737,
      "loss": 3.8719,
      "step": 9000
    },
    {
      "epoch": 0.0955691616169042,
      "grad_norm": 3.5095183849334717,
      "learning_rate": 0.0001808882680977536,
      "loss": 4.0358,
      "step": 9100
    },
    {
      "epoch": 0.09661937218412292,
      "grad_norm": 2.3045921325683594,
      "learning_rate": 0.00018067822598430986,
      "loss": 3.832,
      "step": 9200
    },
    {
      "epoch": 0.09661937218412292,
      "eval_loss": 4.3652753829956055,
      "eval_runtime": 670.8503,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 9200
    },
    {
      "epoch": 0.09766958275134165,
      "grad_norm": 2.2529022693634033,
      "learning_rate": 0.00018046818387086613,
      "loss": 3.9986,
      "step": 9300
    },
    {
      "epoch": 0.09871979331856037,
      "grad_norm": 3.0214602947235107,
      "learning_rate": 0.00018025814175742238,
      "loss": 3.9954,
      "step": 9400
    },
    {
      "epoch": 0.0997700038857791,
      "grad_norm": 4.794836521148682,
      "learning_rate": 0.00018004809964397862,
      "loss": 4.0865,
      "step": 9500
    },
    {
      "epoch": 0.10082021445299783,
      "grad_norm": 6.416492938995361,
      "learning_rate": 0.0001798380575305349,
      "loss": 4.2147,
      "step": 9600
    },
    {
      "epoch": 0.10082021445299783,
      "eval_loss": 4.502624034881592,
      "eval_runtime": 670.9597,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 9600
    },
    {
      "epoch": 0.10187042502021655,
      "grad_norm": 1.6134742498397827,
      "learning_rate": 0.00017962801541709114,
      "loss": 4.2958,
      "step": 9700
    },
    {
      "epoch": 0.10292063558743528,
      "grad_norm": 1.5573021173477173,
      "learning_rate": 0.0001794179733036474,
      "loss": 4.1364,
      "step": 9800
    },
    {
      "epoch": 0.103970846154654,
      "grad_norm": 4.694345951080322,
      "learning_rate": 0.00017920793119020366,
      "loss": 4.0148,
      "step": 9900
    },
    {
      "epoch": 0.10502105672187273,
      "grad_norm": 2.7830493450164795,
      "learning_rate": 0.0001789978890767599,
      "loss": 4.4179,
      "step": 10000
    },
    {
      "epoch": 0.10502105672187273,
      "eval_loss": 4.315730571746826,
      "eval_runtime": 670.9531,
      "eval_samples_per_second": 0.745,
      "eval_steps_per_second": 0.745,
      "step": 10000
    },
    {
      "epoch": 0.10607126728909146,
      "grad_norm": 2.3157618045806885,
      "learning_rate": 0.00017878784696331615,
      "loss": 4.4457,
      "step": 10100
    },
    {
      "epoch": 0.1071214778563102,
      "grad_norm": 2.1014654636383057,
      "learning_rate": 0.0001785778048498724,
      "loss": 3.756,
      "step": 10200
    },
    {
      "epoch": 0.10817168842352892,
      "grad_norm": 1.7180383205413818,
      "learning_rate": 0.00017836776273642864,
      "loss": 3.9197,
      "step": 10300
    },
    {
      "epoch": 0.10922189899074765,
      "grad_norm": 0.9928717017173767,
      "learning_rate": 0.00017815772062298492,
      "loss": 4.0836,
      "step": 10400
    },
    {
      "epoch": 0.10922189899074765,
      "eval_loss": 4.357468605041504,
      "eval_runtime": 571.8713,
      "eval_samples_per_second": 0.874,
      "eval_steps_per_second": 0.874,
      "step": 10400
    },
    {
      "epoch": 0.4410884382318655,
      "grad_norm": 1.3772196769714355,
      "learning_rate": 0.00011179164041167822,
      "loss": 3.9286,
      "step": 10500
    },
    {
      "epoch": 0.4452892805007404,
      "grad_norm": 0.6016159653663635,
      "learning_rate": 0.00011095148078134848,
      "loss": 3.9898,
      "step": 10600
    },
    {
      "epoch": 0.4494901227696153,
      "grad_norm": 1.9084893465042114,
      "learning_rate": 0.00011011132115101869,
      "loss": 3.9588,
      "step": 10700
    },
    {
      "epoch": 0.4536909650384902,
      "grad_norm": 0.872536301612854,
      "learning_rate": 0.00010927116152068895,
      "loss": 3.9856,
      "step": 10800
    },
    {
      "epoch": 0.4536909650384902,
      "eval_loss": 4.223438262939453,
      "eval_runtime": 454.8962,
      "eval_samples_per_second": 1.099,
      "eval_steps_per_second": 0.275,
      "step": 10800
    },
    {
      "epoch": 0.4578918073073651,
      "grad_norm": 1.6937910318374634,
      "learning_rate": 0.00010843100189035917,
      "loss": 4.1217,
      "step": 10900
    },
    {
      "epoch": 0.46209264957624,
      "grad_norm": 1.7369201183319092,
      "learning_rate": 0.0001075908422600294,
      "loss": 3.9698,
      "step": 11000
    },
    {
      "epoch": 0.4662934918451149,
      "grad_norm": 0.9090501070022583,
      "learning_rate": 0.00010675068262969965,
      "loss": 3.9835,
      "step": 11100
    },
    {
      "epoch": 0.47049433411398983,
      "grad_norm": 1.4878215789794922,
      "learning_rate": 0.00010591052299936988,
      "loss": 4.1176,
      "step": 11200
    },
    {
      "epoch": 0.47049433411398983,
      "eval_loss": 4.235755920410156,
      "eval_runtime": 249.5242,
      "eval_samples_per_second": 2.004,
      "eval_steps_per_second": 0.501,
      "step": 11200
    },
    {
      "epoch": 0.4746951763828648,
      "grad_norm": 0.8448818325996399,
      "learning_rate": 0.00010507036336904012,
      "loss": 3.9788,
      "step": 11300
    },
    {
      "epoch": 0.4788960186517397,
      "grad_norm": 0.8146568536758423,
      "learning_rate": 0.00010423020373871035,
      "loss": 4.1473,
      "step": 11400
    },
    {
      "epoch": 0.4830968609206146,
      "grad_norm": 1.200537919998169,
      "learning_rate": 0.0001033900441083806,
      "loss": 4.0501,
      "step": 11500
    },
    {
      "epoch": 0.4872977031894895,
      "grad_norm": 0.9888105988502502,
      "learning_rate": 0.00010254988447805083,
      "loss": 3.9539,
      "step": 11600
    },
    {
      "epoch": 0.4872977031894895,
      "eval_loss": 4.207310676574707,
      "eval_runtime": 460.0005,
      "eval_samples_per_second": 1.087,
      "eval_steps_per_second": 0.272,
      "step": 11600
    },
    {
      "epoch": 0.4914985454583644,
      "grad_norm": 2.0307199954986572,
      "learning_rate": 0.00010170972484772108,
      "loss": 4.0937,
      "step": 11700
    },
    {
      "epoch": 0.4956993877272393,
      "grad_norm": 1.2872930765151978,
      "learning_rate": 0.00010086956521739131,
      "loss": 3.7747,
      "step": 11800
    },
    {
      "epoch": 0.4999002299961142,
      "grad_norm": 0.7329404354095459,
      "learning_rate": 0.00010002940558706155,
      "loss": 4.0529,
      "step": 11900
    },
    {
      "epoch": 0.5041010722649891,
      "grad_norm": 1.0548268556594849,
      "learning_rate": 9.918924595673178e-05,
      "loss": 4.1824,
      "step": 12000
    },
    {
      "epoch": 0.5041010722649891,
      "eval_loss": 4.202101707458496,
      "eval_runtime": 460.2207,
      "eval_samples_per_second": 1.086,
      "eval_steps_per_second": 0.272,
      "step": 12000
    }
  ],
  "logging_steps": 100,
  "max_steps": 23805,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 400,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.8482190278656e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
